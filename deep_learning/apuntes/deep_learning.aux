\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\catcode `<\active 
\catcode `>\active 
\@nameuse{es@quoting}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{spanish}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Definición y Conceptos Clave}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Historia DL}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Factores del Auge Actual}{1}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Aplicaciones Principales}{2}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Desafíos y Ética}{2}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Desafíos Técnicos}{2}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Consideraciones Éticas}{2}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}El Perceptrón: La Unidad Básica de las Redes Neuronales}{2}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Estructura del Perceptrón}{2}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Salida del Perceptrón}{3}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Forma Matricial}{3}{subsection.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Limitaciones del Perceptrón Simple}{3}{subsection.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {7}Funciones de Activación}{4}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}¿Por Qué Necesitamos Funciones de Activación?}{4}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Características Clave de las Funciones de Activación}{4}{subsection.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Funciones de Activación Comunes}{4}{subsection.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4}Uso en Capas de Salida vs. Capas Ocultas}{5}{subsection.7.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Redes Neuronales Totalmente Conectadas (Fully Connected Networks)}{5}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Capas Totalmente Conectadas}{6}{subsection.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Construcción de una Red Totalmente Conectada}{6}{subsection.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Flujo de Información (Forward Pass)}{6}{subsection.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.4}Generalización a Múltiples Capas}{7}{subsection.8.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.5}Multiplicación de Matrices}{7}{subsection.8.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.6}Simplificación de la Notación (Opcional)}{7}{subsection.8.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.7}Número de Parámetros}{7}{subsection.8.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Función de Pérdida (Loss Function): Midiendo el Error}{7}{section.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}¿Qué es la Función de Pérdida?}{7}{subsection.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Características de una Buena Función de Pérdida}{8}{subsection.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}Un Ejemplo Práctico: La Puerta XOR}{8}{subsection.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4}Tipos de Funciones de Pérdida}{8}{subsection.9.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.4.1}Clasificación}{8}{subsubsection.9.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.4.2}Regresión}{9}{subsubsection.9.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5}Interpretación de la Función de Pérdida}{9}{subsection.9.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10}Descenso de Gradiente y Retropropagación (Backpropagation)}{10}{section.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Entrenamiento de una Red Neuronal: El Objetivo}{10}{subsection.10.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}Descenso de Gradiente (Gradient Descent)}{10}{subsection.10.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.2.1}El Gradiente}{10}{subsubsection.10.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.2.2}El Algoritmo}{10}{subsubsection.10.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.2.3}Tasa de Aprendizaje (Learning Rate)}{11}{subsubsection.10.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.2.4}Inicialización de Pesos}{11}{subsubsection.10.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3}Retropropagación (Backpropagation)}{11}{subsection.10.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.3.1}La Regla de la Cadena}{11}{subsubsection.10.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.3.2}Aplicación a la Red Neuronal}{11}{subsubsection.10.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.4}Tipos de Descenso de Gradiente}{12}{subsection.10.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11}El Problema del Desvanecimiento del Gradiente (Vanishing Gradient Problem)}{12}{section.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1}¿Qué es el Desvanecimiento del Gradiente?}{12}{subsection.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2}Causas del Desvanecimiento del Gradiente}{12}{subsection.11.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.3}Consecuencias}{13}{subsection.11.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.4}Soluciones}{13}{subsection.11.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {12}Entrenamiento de una Red Neuronal}{13}{section.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1}Pasos Previos al Entrenamiento}{13}{subsection.12.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2}El Ciclo de Entrenamiento}{14}{subsection.12.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3}Evaluación Final}{15}{subsection.12.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13}Algoritmos de Optimización}{15}{section.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1}Repaso del Descenso de Gradiente}{15}{subsection.13.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.2}Descenso de Gradiente con Momento (Momentum)}{16}{subsection.13.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3}Adam (Adaptive Moment Estimation)}{16}{subsection.13.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.4}Otros Algoritmos de Optimización}{17}{subsection.13.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {14}El Compromiso Sesgo-Varianza (Bias-Variance Tradeoff)}{18}{section.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.1}Sesgo (Bias)}{18}{subsection.14.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2}Varianza (Variance)}{18}{subsection.14.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.3}El Compromiso}{18}{subsection.14.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.4}Representación Gráfica}{18}{subsection.14.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.5}Compromiso Sesgo-Varianza y Redes Neuronales}{19}{subsection.14.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.6}Técnicas para Abordar el Compromiso Sesgo-Varianza}{19}{subsection.14.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15}Regularización: L1, L2 y Dropout}{19}{section.15}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.1}¿Qué es la Regularización?}{20}{subsection.15.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.2}Regularización L1 (Lasso)}{20}{subsection.15.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.3}Regularización L2 (Ridge)}{20}{subsection.15.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.4}Comparación entre L1 y L2}{21}{subsection.15.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {15.5}Dropout}{21}{subsection.15.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {16}Batch Normalization}{22}{section.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {16.1}El Problema del Internal Covariate Shift}{22}{subsection.16.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {16.2}¿Cómo Funciona Batch Normalization?}{22}{subsection.16.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {16.3}Batch Normalization en la Fase de Inferencia (Test)}{23}{subsection.16.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {16.4}Posición de la Capa de Batch Normalization}{23}{subsection.16.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {16.5}Beneficios de Batch Normalization}{23}{subsection.16.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {17}Otras Estrategias Importantes en el Entrenamiento de Redes Neuronales}{23}{section.17}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {17.1}Parada Temprana (Early Stopping)}{23}{subsection.17.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {17.2}Aumento de Datos (Data Augmentation)}{24}{subsection.17.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {17.3}Inicialización de Pesos}{25}{subsection.17.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {18}Redes Convolucionales (Convolutional Neural Networks - CNNs)}{25}{section.18}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {18.1}Introducción}{25}{subsection.18.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {18.2}Motivación: Limitaciones de las Redes Totalmente Conectadas para Imágenes}{25}{subsection.18.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {18.3}Tareas de Visión Artificial}{26}{subsection.18.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {18.4}Historia Breve de las CNNs}{26}{subsection.18.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {18.5}Estructura General de una CNN}{26}{subsection.18.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {19}Diseño de Arquitecturas de Redes Convolucionales}{27}{section.19}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {19.1}Arquitectura General}{27}{subsection.19.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {19.2}Componentes Clave y sus Hiperparámetros}{27}{subsection.19.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {19.2.1}Capa Convolucional (CONV)}{27}{subsubsection.19.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {19.2.2}Capa de Pooling (POOL)}{28}{subsubsection.19.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {19.2.3}Capa Totalmente Conectada (FC)}{28}{subsubsection.19.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {19.2.4}Capa de Aplanamiento (Flatten)}{28}{subsubsection.19.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {19.2.5}Capa de Agrupamiento Global (Global Pooling)}{29}{subsubsection.19.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {19.3}Recomendaciones Generales para el Diseño}{29}{subsection.19.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {20}Principales Arquitecturas de Redes Convolucionales}{29}{section.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {20.1}ImageNet y el ILSVRC}{29}{subsection.20.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {20.2}Arquitecturas Clave}{30}{subsection.20.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {20.2.1}LeNet-5 (1998)}{30}{subsubsection.20.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {20.2.2}AlexNet (2012)}{30}{subsubsection.20.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {20.2.3}ZFNet (2013)}{30}{subsubsection.20.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {20.2.4}VGGNet (2014)}{31}{subsubsection.20.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {20.2.5}GoogLeNet (Inception) (2014)}{31}{subsubsection.20.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {20.2.6}ResNet (Residual Network) (2015)}{31}{subsubsection.20.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {20.2.7}DenseNet (Densely Connected Convolutional Network) (2017)}{32}{subsubsection.20.2.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {20.2.8}MobileNet (2017)}{32}{subsubsection.20.2.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {20.2.9}EfficientNet (2019)}{32}{subsubsection.20.2.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {20.2.10}Vision Transformers (ViT) (2020)}{32}{subsubsection.20.2.10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {21}Entrenamiento y Visualización de Redes Convolucionales}{33}{section.21}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {21.1}Entrenamiento de una CNN: Repaso y Consideraciones}{33}{subsection.21.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {21.2}Hiperparámetros vs. Parámetros}{33}{subsection.21.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {21.3}Estrategias para Evitar el Sobreajuste}{33}{subsection.21.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {21.4}Aumento de Datos (Data Augmentation)}{34}{subsection.21.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {21.5}Tipos de Entrenamiento}{34}{subsection.21.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {21.6}Conjuntos de Datos Comunes para Visión Artificial}{34}{subsection.21.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {21.7}Visualización de Redes Convolucionales}{34}{subsection.21.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {22}Redes Convolucionales para Detección de Objetos}{35}{section.22}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {22.1}Diferencias entre Clasificación y Detección}{35}{subsection.22.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {22.2}Componentes de un Sistema de Detección de Objetos}{35}{subsection.22.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {22.3}Propuesta de Regiones}{35}{subsection.22.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {22.4}Predicciones de la Red}{36}{subsection.22.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {22.5}Supresión No Máxima (Non-Maximum Suppression, NMS)}{36}{subsection.22.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {22.6}Métricas de Evaluación}{36}{subsection.22.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {22.7}Conjuntos de Datos para Detección de Objetos}{36}{subsection.22.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {22.8}Métodos de Detección de Objetos}{37}{subsection.22.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {22.9}Familia R-CNN: Métodos de Dos Etapas}{37}{subsection.22.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {22.10}YOLO y SSD: Métodos de Una Etapa}{38}{subsection.22.10}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {23}Redes Convolucionales para Segmentación Semántica}{38}{section.23}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {23.1}Conceptos Clave}{38}{subsection.23.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {23.2}Arquitecturas para Segmentación Semántica}{39}{subsection.23.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {23.2.1}Redes Completamente Convolucionales (Fully Convolutional Networks - FCNs)}{39}{subsubsection.23.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {23.2.2}Operaciones de Upsampling}{39}{subsubsection.23.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {23.2.3}Arquitecturas Codificador-Decodificador}{39}{subsubsection.23.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {23.3}Métricas de Evaluación}{40}{subsection.23.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {23.4}Funciones de Pérdida}{40}{subsection.23.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {23.5}Conjuntos de Datos}{40}{subsection.23.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {24}Segmentación de Instancias y Segmentación Panóptica}{40}{section.24}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {24.1}Segmentación de Instancias}{41}{subsection.24.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {24.1.1}Mask R-CNN}{41}{subsubsection.24.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {24.2}Segmentación Panóptica}{41}{subsection.24.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {24.3}Métricas de Evaluación}{42}{subsection.24.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {24.4}Conjuntos de Datos}{42}{subsection.24.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {24.5}Modelos Avanzados: OneFormer}{43}{subsection.24.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {25}Redes Neuronales Recurrentes (RNNs): Fundamentos y Arquitecturas}{43}{section.25}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {25.1}Introducción}{43}{subsection.25.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {25.2}¿Qué son las RNNs?}{43}{subsection.25.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {25.3}¿Para qué sirven las RNNs?}{43}{subsection.25.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {25.4}Formulación Matemática de una RNN Simple}{43}{subsection.25.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {25.5}Despliegue en el Tiempo (Unfolding)}{44}{subsection.25.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {25.6}Entrenamiento de una RNN Backpropagation Through Time (BPTT)}{44}{subsection.25.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {25.7}Desafíos del Entrenamiento de RNNs: Desvanecimiento y Explosión del Gradiente}{44}{subsection.25.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {25.8}Tipos de Arquitecturas RNN}{45}{subsection.25.8}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {26}Redes Recurrentes: GRU, LSTM y Bidireccionales}{45}{section.26}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {26.1}Gated Recurrent Unit (GRU)}{45}{subsection.26.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {26.1.1}Componentes de una GRU}{45}{subsubsection.26.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {26.1.2}Ecuaciones de una GRU}{45}{subsubsection.26.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {26.2}Long Short-Term Memory (LSTM)}{46}{subsection.26.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {26.2.1}Componentes de una LSTM}{46}{subsubsection.26.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {26.2.2}Ecuaciones de una LSTM}{47}{subsubsection.26.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {26.3}RNNs Bidireccionales (Bidirectional RNNs - BRNNs)}{47}{subsection.26.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {27}Transformers y Mecanismos de Atención}{47}{section.27}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {27.1}Motivación: Limitaciones de las RNNs en Secuencias Largas}{48}{subsection.27.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {27.2}Mecanismos de Atención (Attention Mechanisms)}{48}{subsection.27.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {27.3}Self-Attention (Auto-Atención)}{48}{subsection.27.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {27.3.1}Componentes de Self-Attention}{48}{subsubsection.27.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {27.3.2}Cálculo de la Atención}{49}{subsubsection.27.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {27.4}Mejoras al Self-Attention Básico (Utilizadas en los Transformers)}{49}{subsection.27.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {27.5}Cross-Attention}{50}{subsection.27.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {27.6}Resumen de Self-Attention (con mejoras)}{50}{subsection.27.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {28}Transformers: Arquitectura y Aplicaciones}{50}{section.28}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {28.1}Arquitectura del Transformer}{50}{subsection.28.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {28.1.1}Encoder-Decoder}{50}{subsubsection.28.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {28.1.2}Componentes del Encoder}{51}{subsubsection.28.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {28.1.3}Componentes del Decoder}{51}{subsubsection.28.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {28.1.4}Positional Encoding}{51}{subsubsection.28.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {28.2}Ventajas de los Transformers sobre las RNNs}{52}{subsection.28.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {28.3}Aplicaciones de los Transformers}{52}{subsection.28.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {29}Aprendizaje No Supervisado y Autoencoders}{52}{section.29}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {29.1}Aprendizaje No Supervisado}{53}{subsection.29.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {29.2}Autoencoders}{53}{subsection.29.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {29.2.1}Arquitectura de un Autoencoder}{53}{subsubsection.29.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {29.2.2}Función de Pérdida}{53}{subsubsection.29.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {29.2.3}Deep Autoencoders}{53}{subsubsection.29.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {29.2.4}Ejemplo: Autoencoder para MNIST}{54}{subsubsection.29.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {29.3}Aplicaciones de los Autoencoders}{54}{subsection.29.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {29.4}Interpolación en el Espacio Latente}{54}{subsection.29.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {30}Redes Generativas Adversarias (Generative Adversarial Networks - GANs)}{54}{section.30}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {30.1}Introducción y Motivación}{54}{subsection.30.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {30.2}Concepto de GAN}{55}{subsection.30.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {30.3}Arquitectura y Funcionamiento}{55}{subsection.30.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {30.4}Entrenamiento de una GAN}{55}{subsection.30.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {30.5}Problemas del Entrenamiento de GANs}{56}{subsection.30.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {30.6}Aplicaciones de las GANs}{56}{subsection.30.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {30.7}Tipos de GANs (solo nombrar, sin detalle)}{56}{subsection.30.7}\protected@file@percent }
\gdef \@abspage@last{56}
